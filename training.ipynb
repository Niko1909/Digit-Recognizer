{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('train.csv')\n",
    "X = data.drop('label', axis=1)\n",
    "X = tf.convert_to_tensor(X)\n",
    "\n",
    "y = data.label\n",
    "y = tf.convert_to_tensor(y)\n",
    "\n",
    "# split data\n",
    "X_train, X_valid = X[:30000], X[30000:]\n",
    "y_train, y_valid = y[:30000], y[30000:]\n",
    "\n",
    "# reshape data\n",
    "X_train = tf.reshape(X_train, [30000, 28, 28, 1])\n",
    "X_valid = tf.reshape(X_valid, [12000, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 1: basic model\n",
    "def build_model1(X_train, X_valid, y_train, y_valid):\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[28, 28, 1]),\n",
    "        layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(units=64, activation='relu'),\n",
    "        layers.Dense(units=10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    history = model.fit(x=X_train, y=y_train, epochs=1, validation_data=(X_valid, y_valid), verbose=1)\n",
    "    history_frame = pd.DataFrame(history.history)\n",
    "    return model, history_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niko-\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.8424 - loss: 2.5198 - val_accuracy: 0.9703 - val_loss: 0.1100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.927733</td>\n",
       "      <td>0.573757</td>\n",
       "      <td>0.970333</td>\n",
       "      <td>0.110041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy      loss  val_accuracy  val_loss\n",
       "0  0.927733  0.573757      0.970333  0.110041"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1, history = build_model1(X_train, X_valid, y_train, y_valid)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 2: basic model with max pooling - improved training time greatly and accuracy slightly\n",
    "def build_model2(X_train, X_valid, y_train, y_valid):\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[28, 28, 1]),\n",
    "        layers.MaxPooling2D(padding='same'),\n",
    "        layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPooling2D(padding='same'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(units=64, activation='relu'),\n",
    "        layers.Dense(units=10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    history = model.fit(x=X_train, y=y_train, epochs=1, validation_data=(X_valid, y_valid), verbose=1)\n",
    "    history_frame = pd.DataFrame(history.history)\n",
    "    return model, history_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niko-\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8321 - loss: 1.8075 - val_accuracy: 0.9741 - val_loss: 0.0872\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9242</td>\n",
       "      <td>0.464541</td>\n",
       "      <td>0.974083</td>\n",
       "      <td>0.087192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy      loss  val_accuracy  val_loss\n",
       "0    0.9242  0.464541      0.974083  0.087192"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2, history = build_model2(X_train, X_valid, y_train, y_valid) \n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 3: builds on iteration 2 with batch normalization and dropout - improved accuracy (prevents overfitting)\n",
    "def build_model3(X_train, X_valid, y_train, y_valid):\n",
    "    model = keras.Sequential([\n",
    "        layers.BatchNormalization(input_shape=[28, 28, 1]),\n",
    "        layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPooling2D(padding='same'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPooling2D(padding='same'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(units=64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(units=10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    history = model.fit(x=X_train, y=y_train, epochs=10, validation_data=(X_valid, y_valid), verbose=1, callbacks=[callback])\n",
    "    history_frame = pd.DataFrame(history.history)\n",
    "    return model, history_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niko-\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:143: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8525 - loss: 0.4938 - val_accuracy: 0.9817 - val_loss: 0.0638\n",
      "Epoch 2/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9722 - loss: 0.0996 - val_accuracy: 0.9859 - val_loss: 0.0480\n",
      "Epoch 3/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9785 - loss: 0.0731 - val_accuracy: 0.9882 - val_loss: 0.0381\n",
      "Epoch 4/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9840 - loss: 0.0541 - val_accuracy: 0.9846 - val_loss: 0.0517\n",
      "Epoch 5/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9844 - loss: 0.0508 - val_accuracy: 0.9893 - val_loss: 0.0349\n",
      "Epoch 6/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9869 - loss: 0.0396 - val_accuracy: 0.9864 - val_loss: 0.0424\n",
      "Epoch 7/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9881 - loss: 0.0363 - val_accuracy: 0.9904 - val_loss: 0.0314\n",
      "Epoch 8/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9890 - loss: 0.0349 - val_accuracy: 0.9898 - val_loss: 0.0314\n",
      "Epoch 9/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.9885 - loss: 0.0323 - val_accuracy: 0.9898 - val_loss: 0.0307\n",
      "Epoch 10/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.0299 - val_accuracy: 0.9893 - val_loss: 0.0320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.926433</td>\n",
       "      <td>0.253991</td>\n",
       "      <td>0.981667</td>\n",
       "      <td>0.063841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973067</td>\n",
       "      <td>0.094766</td>\n",
       "      <td>0.985917</td>\n",
       "      <td>0.047967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.977400</td>\n",
       "      <td>0.073989</td>\n",
       "      <td>0.988167</td>\n",
       "      <td>0.038116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.982067</td>\n",
       "      <td>0.059311</td>\n",
       "      <td>0.984583</td>\n",
       "      <td>0.051669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.984400</td>\n",
       "      <td>0.051222</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.985867</td>\n",
       "      <td>0.042212</td>\n",
       "      <td>0.986417</td>\n",
       "      <td>0.042385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.987700</td>\n",
       "      <td>0.038878</td>\n",
       "      <td>0.990417</td>\n",
       "      <td>0.031448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.989000</td>\n",
       "      <td>0.034580</td>\n",
       "      <td>0.989833</td>\n",
       "      <td>0.031405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.035628</td>\n",
       "      <td>0.989750</td>\n",
       "      <td>0.030682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.989267</td>\n",
       "      <td>0.032780</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.032013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy      loss  val_accuracy  val_loss\n",
       "0  0.926433  0.253991      0.981667  0.063841\n",
       "1  0.973067  0.094766      0.985917  0.047967\n",
       "2  0.977400  0.073989      0.988167  0.038116\n",
       "3  0.982067  0.059311      0.984583  0.051669\n",
       "4  0.984400  0.051222      0.989333  0.034918\n",
       "5  0.985867  0.042212      0.986417  0.042385\n",
       "6  0.987700  0.038878      0.990417  0.031448\n",
       "7  0.989000  0.034580      0.989833  0.031405\n",
       "8  0.988000  0.035628      0.989750  0.030682\n",
       "9  0.989267  0.032780      0.989333  0.032013"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3, history = build_model3(X_train, X_valid, y_train, y_valid) \n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 4: build on iteration 3 with data augmentation\n",
    "def build_model4(X_train, X_valid, y_train, y_valid):\n",
    "    data_aug = keras.Sequential([\n",
    "        layers.Rescaling(scale=1./255),\n",
    "        layers.RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)),\n",
    "        layers.RandomRotation(factor=(-0.1, 0.1)),\n",
    "        layers.RandomContrast(factor=(0.1, 0.2))\n",
    "    ])\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        data_aug,\n",
    "        layers.BatchNormalization(input_shape=[28, 28, 1]),\n",
    "        layers.Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPooling2D(padding='same'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPooling2D(padding='same'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(units=64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(units=10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    history = model.fit(x=X_train, y=y_train, epochs=15, validation_data=(X_valid, y_valid), verbose=1, callbacks=[callback])\n",
    "    history_frame = pd.DataFrame(history.history)\n",
    "    return model, history_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niko-\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:143: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.7707 - loss: 0.7239 - val_accuracy: 0.9731 - val_loss: 0.0856\n",
      "Epoch 2/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9346 - loss: 0.2200 - val_accuracy: 0.9794 - val_loss: 0.0647\n",
      "Epoch 3/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.9499 - loss: 0.1582 - val_accuracy: 0.9830 - val_loss: 0.0558\n",
      "Epoch 4/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.9582 - loss: 0.1393 - val_accuracy: 0.9846 - val_loss: 0.0512\n",
      "Epoch 5/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9613 - loss: 0.1260 - val_accuracy: 0.9881 - val_loss: 0.0408\n",
      "Epoch 6/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9641 - loss: 0.1168 - val_accuracy: 0.9853 - val_loss: 0.0482\n",
      "Epoch 7/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9691 - loss: 0.1058 - val_accuracy: 0.9870 - val_loss: 0.0426\n",
      "Epoch 8/15\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.9689 - loss: 0.1018 - val_accuracy: 0.9874 - val_loss: 0.0413\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.868567</td>\n",
       "      <td>0.423209</td>\n",
       "      <td>0.973083</td>\n",
       "      <td>0.085576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.938400</td>\n",
       "      <td>0.201969</td>\n",
       "      <td>0.979417</td>\n",
       "      <td>0.064698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.951667</td>\n",
       "      <td>0.156078</td>\n",
       "      <td>0.983000</td>\n",
       "      <td>0.055835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.958467</td>\n",
       "      <td>0.135344</td>\n",
       "      <td>0.984583</td>\n",
       "      <td>0.051234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.962400</td>\n",
       "      <td>0.123491</td>\n",
       "      <td>0.988083</td>\n",
       "      <td>0.040761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.965867</td>\n",
       "      <td>0.114414</td>\n",
       "      <td>0.985333</td>\n",
       "      <td>0.048173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.967667</td>\n",
       "      <td>0.107736</td>\n",
       "      <td>0.987000</td>\n",
       "      <td>0.042616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.968800</td>\n",
       "      <td>0.099723</td>\n",
       "      <td>0.987417</td>\n",
       "      <td>0.041313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy      loss  val_accuracy  val_loss\n",
       "0  0.868567  0.423209      0.973083  0.085576\n",
       "1  0.938400  0.201969      0.979417  0.064698\n",
       "2  0.951667  0.156078      0.983000  0.055835\n",
       "3  0.958467  0.135344      0.984583  0.051234\n",
       "4  0.962400  0.123491      0.988083  0.040761\n",
       "5  0.965867  0.114414      0.985333  0.048173\n",
       "6  0.967667  0.107736      0.987000  0.042616\n",
       "7  0.968800  0.099723      0.987417  0.041313"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4, history = build_model4(X_train, X_valid, y_train, y_valid) \n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration 5: pretrained base with trainable head using the augmentation from iteration 4\n",
    "\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "def create_dataset(X_train, y_train, X_valid, y_valid):\n",
    "    data_aug = keras.Sequential([\n",
    "        layers.Rescaling(scale=1./255),\n",
    "        layers.RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)),\n",
    "        layers.RandomRotation(factor=(-0.1, 0.1)),\n",
    "        layers.RandomContrast(factor=(0.1, 0.2))\n",
    "    ])\n",
    "    # pass data through data augmentation\n",
    "    X_train = data_aug(X_train)\n",
    "    X_valid = data_aug(X_valid)\n",
    "    # convert to float\n",
    "    X_train = tf.image.convert_image_dtype(X_train, dtype=tf.float32)\n",
    "    X_valid = tf.image.convert_image_dtype(X_valid, dtype=tf.float32)\n",
    "\n",
    "    # create dataset and reshape data\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    valid_ds = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "    train_ds = train_ds.map(preprocess_image)\n",
    "    valid_ds = valid_ds.map(preprocess_image)\n",
    "\n",
    "    return train_ds, valid_ds\n",
    "\n",
    "# resize and colourize data for pretrained model\n",
    "def preprocess_image(images, labels):\n",
    "    images = tf.image.resize(images, (224, 224))\n",
    "    images = tf.image.grayscale_to_rgb(images)\n",
    "    return images, labels\n",
    "\n",
    "def build_model5(train_ds, valid_ds):\n",
    "    # add pretrained base model\n",
    "    base = tf.keras.applications.VGG16(include_top=False, weights='imagenet')\n",
    "    base.trainable = False\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        base,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(units=64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(units=10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=valid_ds,\n",
    "        epochs=1,\n",
    "        verbose=0,\n",
    "    )\n",
    "    history_frame = pd.DataFrame(history.history)\n",
    "    return model, history_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, valid_ds = create_dataset(X_train, y_train, X_valid, y_valid)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============CAREFUL: building this model uses a lot of memory (20gb+) and can take hours if using a CPU to train=================\n",
    "\n",
    "# model5, history = build_model5(train_ds, valid_ds) \n",
    "# history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "test_data = pd.read_csv('test.csv')\n",
    "X_test = tf.reshape(test_data, [test_data.shape[0], 28, 28, 1])\n",
    "\n",
    "def make_preds(model, X_test):\n",
    "    preds = model.predict(X_test)\n",
    "    preds = [tf.argmax(pred).numpy() for pred in preds]\n",
    "    label = [i for i in range(1, len(preds)+1)]\n",
    "    return pd.concat([pd.Series(label), pd.Series(preds)], axis=1, keys=['ImageId', 'Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "submission1 = make_preds(model1, X_test)\n",
    "submission1.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "submission2 = make_preds(model2, X_test)\n",
    "submission2.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "submission3 = make_preds(model3, X_test)\n",
    "submission3.to_csv('submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "submission4 = make_preds(model4, X_test)\n",
    "submission4.to_csv('submission4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
